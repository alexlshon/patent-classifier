{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patent Classifier \n",
    "\n",
    "Patent classification is a challenging task due to large number of possible subject matters that a patent can be classified into. This challenge is compounded by the high level of technical vocabulary and the large size of the patent document which leads to high dimensional predictor vectors. Using natural language processing and word vectoriztion, A model is to be generated that can correctly classify patents into their correct patent classification. The dataset of patents used is about 50 GB whichs adds considerable challenges in modeling due to its size. Challenges that are met using apache spark, A analytical framework that specializes in computing big data. Using apache spark, patents split into training and testing groups. Navie Bayes and cosine similarity models are fitted on the training data and transformed on the testing data. The models are then scored using accuarcy. The scores from these relatively simple models are then compaired to scores on more complex BERT model done in the literature.  \n",
    "\n",
    "## Introduction And Background  \n",
    "\n",
    "### Patent Classification \n",
    "Any effective method of patent classification by technical subject matter must have and balance the following three properties.\n",
    " - Cover the entire range of possible technical subject matter \n",
    " - Have enought granularity to distinguish related patents\n",
    " - Yet not too much granularity such that it is no longer an useful abstraction \n",
    " \n",
    "A patent classification system that maximizes granularity simiply gives each unique patent its own unique classification. One that minimizes granularity simiply classifies all the patents into one subject matter. Since the number of possible subject matters is extreamly large, neither of these systems are useful abstractions. A more useful system would have a small number of classes. The most useful system would recursively chain together multiple medium granularity classification systems in a hierarchical manner. The number of recursions will be dependant on the level of granularity one wants to reach. A simple classification will require one or two recursions while an advanced classification will need alteast a few. Lets say we want to classify patents into a thousand categories. Instead of trying the classifiy the patents into a thousand different categories at once, we classify only 10 categories with each category classified into 10 sub-categories. Each sub-category is then classified further into 10 sub-sub-categories. Using the recursive method to classify yeilds an hierarchical classification system. Such Hierarchical classification system can be modeled as a Directed Acylic Graph, which is also known as a tree data structure. Many classification systems are structured as hierarchical classification systems. If you are familar with the Dewey Decimal system or the Library of Congress Classification system for classifing books then you are already familar with hierarchical classification systems. All patent classification systems are heriarchical, what differs between patent systems in patent offices of different nations is the categories used for each level. Since 2013, the patent offices of the US and EU have harmonized their patent classification systems called the CPC.\n",
    "\n",
    "The current system of patent classification is the Cooperative Patent Classification CPC) for the United States Patent and Trademark Office (USPTO) and the European Patent Office (EPO). A series of symbols are used to represent the category. When the series is read left to right, The first is symbol represents the highest level of categorization which each symbol to the left representing one level down in categorization. The schema with their represenative symbols for the CPC hierarchies are given below. \n",
    "- Section (one letter A to H and also Y)\n",
    "    - Class (two digits)\n",
    "        - Subclass (one letter)\n",
    "            - Group (one to three digits)\n",
    "                - Main group and subgroups (at least two digits)\n",
    "\n",
    "\n",
    "For example, A recent patent from Google titled *Neural Network Processor*, patent number US20160342891A1, has the primary CPC classification as G06N3/08. Each of the subject matter classifications, for this patent, by level are the following \n",
    "- Section G (Physics)\n",
    "    - Class G06 (Computing; Calculating; Counting)\n",
    "        - Subclass G06N (Computer Systems Based on Specific Computational Models)\n",
    "            - Group G06N3 (Computer Systems Based on Biological Models)\n",
    "                - Main group and subgroups G06N3/08 (Learning Methods)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection and EDA\n",
    "The USPTO has the entire corpus of American patents and patent applications available online. The challenge of the data collection would be the large size of the dataset. A single week worth of patent applications in XML format is 140 megabytes. Currently I am looking for strategies to automate the collection of data and the eventual big data analysis required. I am looking at using polynotes, basically an open source data bricks, with apache spark to handle this large set of data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conculsion \n",
    "\n",
    "## Relevent Links \n",
    "Patent Classification by Fine-Tuning BERT Language Model\n",
    "https://arxiv.org/ftp/arxiv/papers/1906/1906.02124.pdf\n",
    "\n",
    "An Simple Example of Patent Classification \n",
    "http://cs229.stanford.edu/proj2011/ChristopherLinSpieckermann-AutomatedPatentClassification.pdf\n",
    "\n",
    "UER: An Open-Source Toolkit for Pre-training Models\n",
    "https://arxiv.org/pdf/1909.05658.pdf\n",
    "\n",
    "Neural machine translation by jointly learning to align and translate\n",
    "https://arxiv.org/pdf/1409.0473v7.pdf\n",
    "\n",
    "CPC information \n",
    "https://www.cooperativepatentclassification.org/Training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
