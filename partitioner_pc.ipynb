{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "language": "text"
   },
   "source": [
    "# Patent Classifier\n",
    "\n",
    "\n",
    "This is the notebook for prototyping the patent classifier code. The following is the first exploration of the data sets from the USPTO Patent View database. \n",
    "\n",
    "# Data\n",
    "\n",
    "The data is three tab separated variable text files from the USPTO Patent View database. The data sets are relatively large with the largest of the three, the data set containing the claims data, at 40 GB. The next largest data set is the one containing the data about each patent. This data included the title, abstract and date and took up about 6 GB of space. The third and smallest data set contained data the cpc classification info for each patent. The cpc classification file takes up about 4 GB of space. The variance in data sets size are due to both the difference in the number of rows and the ammount of text data in each element. Each of the data sets contain data needed for the patent classification. However, not all of the data from each data set are needed. Only a subset of the data was used in the classification. Thus to simplify our task a new tsv file was created with only the relavent information. This partioned data set is generated in this notebook with the scala code is spark below.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell.metadata.exec_info": {
     "endTs": 1575884544163,
     "startTs": 1575884543549
    },
    "jupyter.outputs_hidden": true,
    "language": "scala"
   },
   "outputs": [
    {
     "ename": "org.apache.spark.sql.AnalysisException",
     "evalue": "Path does not exist: file:/home/alex/Projects/data/cpc_current.tsv;",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "val cpc = spark.read.format(\"csv\")\n",
    "  .option(\"sep\", \"\\t\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .load(\"../Projects/data/cpc_current.tsv\")\n",
    "\n",
    "val patent = spark.read.format(\"csv\")\n",
    "  .option(\"sep\", \"\\t\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .load(\"../Projects/data/patent.tsv\")\n",
    "\n",
    "val claim = spark.read.format(\"csv\")\n",
    "  .option(\"sep\", \"\\t\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .load(\"../Projects/data/claim.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell.metadata.exec_info": {
     "endTs": 1575342405447,
     "startTs": 1575342306817
    },
    "jupyter.source_hidden": true,
    "language": "scala"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39915464\n",
      "7144430\n",
      "101535754\n"
     ]
    }
   ],
   "source": [
    "println(cpc.count())\n",
    "println(patent.count())\n",
    "println(claim.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cell.metadata.exec_info": {
     "endTs": 1575355285746,
     "startTs": 1575355285101
    },
    "jupyter.source_hidden": true,
    "language": "scala"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+----------+-------------+--------+--------------+-----------+--------+\n",
      "|                uuid|patent_id|section_id|subsection_id|group_id|   subgroup_id|   category|sequence|\n",
      "+--------------------+---------+----------+-------------+--------+--------------+-----------+--------+\n",
      "|000016xombd5lbk9l...|  7070831|         H|          H01|    H01L|H01L2924/01013| additional|      22|\n",
      "|000070runw99gxjki...|  7618693|         C|          C09|    C09D|     C09D11/30|inventional|       1|\n",
      "|00008erwm5297s6wv...|  8488869|         G|          G06|    G06T|G06T2207/10016| additional|      20|\n",
      "|00008q01v2ziacpr0...|  9976665|         A|          A61|    A61M|   A61M5/16886|inventional|       4|\n",
      "|00008rwbcfjb44c0m...|  9448251|         H|          H01|    H01L|     H01L29/84|inventional|       6|\n",
      "+--------------------+---------+----------+-------------+--------+--------------+-----------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cpc.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cell.metadata.exec_info": {
     "endTs": 1575355287240,
     "startTs": 1575355286818
    },
    "jupyter.source_hidden": true,
    "language": "scala"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+--------+-------+----------+--------------------+--------------------+----+----------+-------------+---------+\n",
      "|      id|   type|  number|country|      date|            abstract|               title|kind|num_claims|     filename|withdrawn|\n",
      "+--------+-------+--------+-------+----------+--------------------+--------------------+----+----------+-------------+---------+\n",
      "|10000000|utility|10000000|     US|2018-06-19|A frequency modul...|Coherent LADAR us...|  B2|        20|ipg180619.xml|     NULL|\n",
      "|10000001|utility|10000001|     US|2018-06-19|The injection mol...|Injection molding...|  B2|        12|ipg180619.xml|     NULL|\n",
      "|10000002|utility|10000002|     US|2018-06-19|The present inven...|Method for manufa...|  B2|         9|ipg180619.xml|     NULL|\n",
      "|10000003|utility|10000003|     US|2018-06-19|The invention rel...|Method for produc...|  B2|        18|ipg180619.xml|     NULL|\n",
      "|10000004|utility|10000004|     US|2018-06-19|The present inven...|Process of obtain...|  B2|         6|ipg180619.xml|     NULL|\n",
      "+--------+-------+--------+-------+----------+--------------------+--------------------+----+----------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patent.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "cell.metadata.exec_info": {
     "endTs": 1575355289139,
     "startTs": 1575355288709
    },
    "jupyter.source_hidden": true,
    "language": "scala"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+--------------------+---------+--------+---------+\n",
      "|                uuid|patent_id|                text|dependent|sequence|exemplary|\n",
      "+--------------------+---------+--------------------+---------+--------+---------+\n",
      "|00000dv6xkiuyewi5...|  4968079|A golf ball retri...|       -1|       1|     True|\n",
      "|00000w0pl9vz7nts0...|  8266944|4. The method of ...|        3|       4|    False|\n",
      "|00000yv19kqb063az...|  6992283|77. A mass spectr...|       15|      77|    False|\n",
      "|000021tixo539g81a...|  8745515|3. The method acc...|        1|       3|    False|\n",
      "|00002oe7jg97rmmep...|  4149148|The apparatus of ...|       14|      15|    False|\n",
      "+--------------------+---------+--------------------+---------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "claim.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter.outputs_hidden": true,
    "language": "text"
   },
   "source": [
    "The categories needed are patent_id, cpc, claim text, and text. Also needed is to remove repeated elements in the data. This is conducted by concatenating the claims and cpc group_id into one element in the tsv so that each row is an unique patent id number  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "cell.metadata.exec_info": {
     "endTs": 1575499682424,
     "startTs": 1575499681489
    },
    "language": "scala"
   },
   "outputs": [],
   "source": [
    "val grouped_claim = claim.select(\"patent_id\",\"text\")\n",
    "    .groupBy(\"patent_id\")\n",
    "    .agg(concat_ws(\",\",collect_list(\"text\")).alias(\"claims\"))\n",
    "\n",
    "val patent_cpc =patent\n",
    "    .join(cpc,cpc(\"patent_id\")===patent(\"id\"))\n",
    "    .filter(cpc(\"sequence\")===0)\n",
    "    .drop(\"patent_id\")\n",
    "    .select(\"id\",\"group_id\",\"date\")\n",
    "\n",
    "val df = grouped_claim\n",
    "    .join(patent_cpc,patent_cpc(\"id\") === grouped_claim(\"patent_id\"))\n",
    "    .drop(\"patent_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cell.metadata.exec_info": {
     "endTs": 1575494349301,
     "startTs": 1575494003015
    },
    "jupyter.outputs_hidden": true,
    "jupyter.source_hidden": true,
    "language": "scala"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------+----------+\n",
      "|              claims|      id|group_id|      date|\n",
      "+--------------------+--------+--------+----------+\n",
      "|8. The refrigerat...|10000108|    B60H|2018-06-19|\n",
      "|14. The method of...|10000172|    B60R|2018-06-19|\n",
      "|11. The method of...|10000304|    B65B|2018-06-19|\n",
      "|13. The compound ...|10000454|    C07D|2018-06-19|\n",
      "|13. The photochro...|10000472|    C07D|2018-06-19|\n",
      "|5. The method acc...|10000528|    C07K|2018-06-19|\n",
      "|3. The process ac...|10000591|    C08F|2018-06-19|\n",
      "|10. The assembly ...|10000670|    C09J|2018-06-19|\n",
      "|8. A method for r...|10000720|    C10M|2018-06-19|\n",
      "|14. The system of...|10000723|    C11B|2018-06-19|\n",
      "|5. The recombinan...|10000761|    C12N|2018-06-19|\n",
      "|3. The method of ...|10000835|    C22F|2018-06-19|\n",
      "|14. The composite...|10000989|    E21B|2018-06-19|\n",
      "|6. The magazine l...|10001331|    F41A|2018-06-19|\n",
      "|14. The method of...|10001922|    G06F|2018-06-19|\n",
      "|1. A method for v...|10001989|    G06F|2018-06-19|\n",
      "|3. The system as ...|10002011|    G06F|2018-06-19|\n",
      "|2. The method acc...|10002280|    G06K|2018-06-19|\n",
      "|3. A method for o...|10002674|    G11C|2018-06-19|\n",
      "|8. The electronic...|10002811|    H01L|2018-06-19|\n",
      "+--------------------+--------+--------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "language": "text"
   },
   "source": [
    "Here we will save the progress of the partitioned data. We will also count the number of elements in the cpc file that has the value of zero for sequence\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "cell.metadata.exec_info": {
     "endTs": 1575500349724,
     "startTs": 1575499688692
    },
    "language": "scala"
   },
   "outputs": [],
   "source": [
    "val df_saver = df.write.save(\"../Projects/data/partitioned_hdfs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "cell.metadata.exec_info": {
     "endTs": 1575500478297,
     "startTs": 1575500459787
    },
    "jupyter.outputs_hidden": true,
    "language": "scala"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6452079"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "name": "Out",
      "type": "Long"
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpc.filter(col(\"sequence\") === \"0\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "language": "text"
   },
   "source": []
  }
 ],
 "metadata": {
  "config": {
   "dependencies": {},
   "exclusions": [],
   "repositories": [],
   "sparkConfig": {
    "spark.driver.memory": "20g",
    "spark.executor.memory": "20g",
    "spark.local.dir": "~/tem",
    "spark.master": "local[*]"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
