{
  "metadata" : {
    "config" : {
      "dependencies" : {
        
      },
      "exclusions" : [
      ],
      "repositories" : [
      ],
      "sparkConfig" : {
        "spark.executor.memory" : "11g",
        "spark.local.dir" : "~/tem",
        "spark.driver.memory" : "11g",
        "spark.master" : "local[*]"
      }
    }
  },
  "nbformat" : 4,
  "nbformat_minor" : 0,
  "cells" : [
    {
      "cell_type" : "markdown",
      "execution_count" : 0,
      "metadata" : {
        "language" : "text"
      },
      "language" : "text",
      "source" : [
        "# Count VectorizeÂ \n",
        "\n",
        "\n",
        "Count Vectorization is a computationally expensive operation. The step of count vectorization takes about 10 minutes to calculate. Instead of calculating a new count vector every time we conduct a new model, The count vectorization is done once and saved into memory.\n",
        "\n",
        "\n"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 1,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1575875081736,
          "endTs" : 1575875087852
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import org.apache.spark.sql.types.LongType\n",
        "var df = spark.read.format(\"csv\")\n",
        "  .option(\"sep\", \"\\t\")\n",
        "  .option(\"header\", \"true\")\n",
        "  .load(\"../Projects/data/partitioned_hdfs\")\n",
        "  .withColumn(\"id\",col(\"id\").cast(LongType))\n",
        "  .dropDuplicates(\"id\")"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 2,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1575875158464,
          "endTs" : 1575875159951
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "import org.apache.spark.ml.feature\n",
        "    .{VectorAssembler,StringIndexer,Tokenizer, StopWordsRemover, CountVectorizer}\n",
        "import org.apache.spark.ml.Pipeline\n",
        "\n",
        "var indexer = new StringIndexer()\n",
        "    .setInputCol(\"group_id\")\n",
        "    .setOutputCol(\"label\")\n",
        "\n",
        "var tokenizer = new Tokenizer()\n",
        "    .setInputCol(\"claims\")\n",
        "    .setOutputCol(\"tokens\")\n",
        "\n",
        "var remover = new StopWordsRemover()\n",
        "    .setInputCol(tokenizer.getOutputCol)\n",
        "    .setOutputCol(\"sWord\")\n",
        "\n",
        "var cvec = new CountVectorizer()\n",
        "    .setInputCol(remover.getOutputCol)\n",
        "    .setOutputCol(\"cvec\")\n",
        "    .setVocabSize(10000)\n",
        "\n",
        "var assembler = new VectorAssembler()\n",
        "    .setInputCols(Array(cvec.getOutputCol))\n",
        "    .setOutputCol(\"features\")\n",
        "\n",
        "var pipe = new Pipeline()\n",
        "    .setStages(Array(\n",
        "        indexer,\n",
        "        tokenizer,\n",
        "        remover,\n",
        "        cvec,\n",
        "        assembler\n",
        "    ))\n",
        "    "
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 3,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1575875166149,
          "endTs" : 1575876322987
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val cvec = pipe.fit(df)"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 4,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1575876322990,
          "endTs" : 1575876325951
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "val vec_df = cvec.transform(df)"
      ],
      "outputs" : [
      ]
    },
    {
      "cell_type" : "code",
      "execution_count" : 5,
      "metadata" : {
        "cell.metadata.exec_info" : {
          "startTs" : 1575876325957,
          "endTs" : 1575877584345
        },
        "language" : "scala"
      },
      "language" : "scala",
      "source" : [
        "vec_df.select(\"id\",\"label\",\"features\")\n",
        "    .write.save(\"../Projects/data/vec_df_hdfs\")"
      ],
      "outputs" : [
      ]
    }
  ]
}